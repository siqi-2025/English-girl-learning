"""
ä¸»ç•Œé¢æ¨¡å—

è‹±è¯­å­¦ä¹ åŠ©æ‰‹çš„Streamlitä¸»ç•Œé¢
"""

import streamlit as st
import os
from pathlib import Path
from typing import List, Dict, Optional
import time

from ..core.vision_processor import create_vision_processor
from ..core.ai_analyzer import create_ai_enhanced_ocr, test_ai_connection
from ..core.document_generator import DocumentGenerator
from ..utils.config import config


class EnglishLearningInterface:
    """è‹±è¯­å­¦ä¹ åŠ©æ‰‹ä¸»ç•Œé¢"""
    
    def __init__(self):
        self.version = "v1.6.0"
        self.vision_processor = None
        self.ai_analyzer = None
        self.doc_generator = None
        print(f"[EnglishLearningInterface] åˆå§‹åŒ–ç•Œé¢ {self.version}")
        
    def setup_page_config(self):
        """è®¾ç½®é¡µé¢é…ç½®"""
        st.set_page_config(
            page_title="è‹±è¯­å­¦ä¹ åŠ©æ‰‹ - AIå¢å¼ºOCRç³»ç»Ÿ",
            page_icon="ğŸ“š",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # è‡ªå®šä¹‰CSSæ ·å¼
        st.markdown("""
        <style>
        .main-header {
            color: #1f77b4;
            text-align: center;
            font-size: 2.5rem;
            margin-bottom: 2rem;
        }
        .feature-card {
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            padding: 1rem;
            margin: 1rem 0;
            background-color: #f8f9fa;
        }
        .success-message {
            background-color: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
            padding: 0.75rem;
            border-radius: 0.25rem;
            margin: 1rem 0;
        }
        .warning-message {
            background-color: #fff3cd;
            border: 1px solid #ffeaa7;
            color: #856404;
            padding: 0.75rem;
            border-radius: 0.25rem;
            margin: 1rem 0;
        }
        </style>
        """, unsafe_allow_html=True)
    
    def render_header(self):
        """æ¸²æŸ“é¡µé¢å¤´éƒ¨"""
        st.markdown(f'<h1 class="main-header">ğŸ“š è‹±è¯­å­¦ä¹ åŠ©æ‰‹ {self.version}</h1>', unsafe_allow_html=True)
        st.markdown('<p style="text-align: center; font-size: 1.2rem; color: #666;">çº¯AIè§†è§‰è¯†åˆ«ç³»ç»Ÿ + æ™ºèƒ½æ–‡æ¡£ç”Ÿæˆ</p>', unsafe_allow_html=True)
        st.markdown(f'<p style="text-align: center; font-size: 0.9rem; color: #888;">ç‰ˆæœ¬: {self.version} | åŸºäºGLM-4V-Flashçº¯è§†è§‰è¯†åˆ«</p>', unsafe_allow_html=True)
        print(f"[UI] æ¸²æŸ“å¤´éƒ¨ï¼Œç‰ˆæœ¬: {self.version}")
        
        # ç³»ç»ŸçŠ¶æ€æ£€æŸ¥
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if test_ai_connection():
                st.success("ğŸ¤– AIæœåŠ¡è¿æ¥æ­£å¸¸")
            else:
                st.error("âŒ AIæœåŠ¡è¿æ¥å¤±è´¥")
                
        with col2:
            st.success("ğŸ‘ï¸ GLM-4V-Flashè§†è§‰è¯†åˆ«å°±ç»ª")
            print("[UI] GLM-4V-Flashè§†è§‰è¯†åˆ«æ¨¡å—çŠ¶æ€: å°±ç»ª")
                
        with col3:
            api_key = config.get_api_key()
            if api_key:
                st.success("ğŸ”‘ APIå¯†é’¥å·²é…ç½®")
            else:
                st.warning("âš ï¸ è¯·é…ç½®APIå¯†é’¥")
    
    def render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        with st.sidebar:
            st.markdown("### âš™ï¸ ç³»ç»Ÿé…ç½®")
            
            # APIå¯†é’¥é…ç½®
            st.markdown("#### ğŸ”‘ APIè®¾ç½®")
            current_key = config.get_api_key()
            key_status = "âœ… å·²é…ç½®" if current_key else "âŒ æœªé…ç½®"
            st.info(f"å½“å‰çŠ¶æ€: {key_status}")
            
            if st.button("ğŸ”„ é‡æ–°åŠ è½½é…ç½®"):
                st.experimental_rerun()
            
            st.markdown("---")
            
            # è§†è§‰è¯†åˆ«è®¾ç½®
            st.markdown("#### ğŸ‘ï¸ è§†è§‰è¯†åˆ«è®¾ç½®")
            st.info("ä½¿ç”¨GLM-4V-Flashè¿›è¡Œå›¾åƒè¯†åˆ«")
            print("[UI] æ˜¾ç¤ºè§†è§‰è¯†åˆ«è®¾ç½®é¢æ¿")
            
            # AIè®¾ç½®
            st.markdown("#### ğŸ¤– AIè®¾ç½®")
            temperature = st.slider("ç”Ÿæˆæ¸©åº¦", 0.1, 1.0, 0.7, 0.1)
            max_tokens = st.slider("æœ€å¤§ç”Ÿæˆé•¿åº¦", 500, 4000, 2000, 100)
            
            st.markdown("---")
            st.markdown("### ğŸ“Š ä½¿ç”¨ç»Ÿè®¡")
            
            # åˆå§‹åŒ–session state
            if 'processed_count' not in st.session_state:
                st.session_state.processed_count = 0
            if 'generated_docs' not in st.session_state:
                st.session_state.generated_docs = 0
                
            st.metric("å¤„ç†å›¾ç‰‡æ•°", st.session_state.processed_count)
            st.metric("ç”Ÿæˆæ–‡æ¡£æ•°", st.session_state.generated_docs)
            
            return {
                'temperature': temperature,
                'max_tokens': max_tokens
            }
    
    def render_image_upload_section(self, settings: Dict):
        """æ¸²æŸ“å›¾åƒä¸Šä¼ åŒºåŸŸ"""
        st.markdown("### ğŸ“· å›¾åƒå¤„ç†")
        
        # é€‰æ‹©è¾“å…¥æ–¹å¼
        input_method = st.radio(
            "é€‰æ‹©è¾“å…¥æ–¹å¼ï¼š",
            ["ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶", "æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹"],
            horizontal=True
        )
        
        if input_method == "ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶":
            uploaded_files = st.file_uploader(
                "é€‰æ‹©è‹±è¯­æ•™æå›¾ç‰‡",
                type=['png', 'jpg', 'jpeg', 'bmp', 'tiff'],
                accept_multiple_files=True,
                help="æ”¯æŒå¤šç§å›¾ç‰‡æ ¼å¼ï¼Œå¯åŒæ—¶ä¸Šä¼ å¤šä¸ªæ–‡ä»¶"
            )
            
            if uploaded_files:
                # ç®€å•æ˜¾ç¤ºä¸Šä¼ çš„å›¾ç‰‡ï¼Œä¸è°ƒç”¨AI
                return self._display_uploaded_images(uploaded_files)
                
        else:
            folder_path = st.text_input(
                "è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„",
                value=r"D:\360MoveData\Users\wukon\Pictures\7ä¸Šè‹±è¯­",
                help="è¾“å…¥åŒ…å«è‹±è¯­æ•™æå›¾ç‰‡çš„æ–‡ä»¶å¤¹å®Œæ•´è·¯å¾„"
            )
            
            if st.button("ğŸ” æ‰«ææ–‡ä»¶å¤¹"):
                if os.path.exists(folder_path):
                    return self._process_folder(folder_path, settings)
                else:
                    st.error("æ–‡ä»¶å¤¹è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
        
        return None
    
    def _process_uploaded_files(self, uploaded_files: List, settings: Dict) -> Optional[Dict]:
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        if not uploaded_files:
            return None
            
        st.info(f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        if st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary"):
            print(f"\n{'='*80}")
            print(f"[ä¸»æµç¨‹] ğŸš€ ç”¨æˆ·ç‚¹å‡»å¼€å§‹å¤„ç†æŒ‰é’®")
            print(f"[ä¸»æµç¨‹] ç³»ç»Ÿç‰ˆæœ¬: {self.version}")
            print(f"[ä¸»æµç¨‹] å¾…å¤„ç†æ–‡ä»¶æ•°é‡: {len(uploaded_files)}")
            print(f"[ä¸»æµç¨‹] å½“å‰æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"{'='*80}")
            st.write("**ğŸ”„ å¼€å§‹å¤„ç†ï¼ŒæŸ¥çœ‹æ§åˆ¶å°è·å–è¯¦ç»†æ—¥å¿—...**")
            
            # åˆå§‹åŒ–å¤„ç†å™¨
            if not self._initialize_processors():
                print(f"[å¤„ç†] å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥")
                return None
            else:
                print(f"[å¤„ç†] å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
                
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, uploaded_file in enumerate(uploaded_files):
                status_text.text(f"æ­£åœ¨å¤„ç†: {uploaded_file.name}")
                
                try:
                    # è°ƒè¯•ï¼šæ£€æŸ¥å¤„ç†å™¨çŠ¶æ€
                    print(f"[è°ƒè¯•] vision_processorå­˜åœ¨: {self.vision_processor is not None}")
                    print(f"[è°ƒè¯•] ai_analyzerå­˜åœ¨: {self.ai_analyzer is not None}")
                    
                    # æ­¥éª¤1: GLM-4V-Flashè§†è§‰è¯†åˆ«
                    status_text.text(f"ğŸ” æ­¥éª¤1: GLM-4V-Flashè§†è§‰è¯†åˆ« - {uploaded_file.name}")
                    print(f"\n[ç¬¬{i+1}æ­¥] ==================== å¼€å§‹å¤„ç†æ–‡ä»¶ ====================")
                    print(f"[ç¬¬{i+1}æ­¥] ğŸ“ æ–‡ä»¶å: {uploaded_file.name}")
                    print(f"[ç¬¬{i+1}æ­¥] ğŸ“Š æ–‡ä»¶å¤§å°: {uploaded_file.size} bytes")
                    print(f"[ç¬¬{i+1}æ­¥] ğŸ¯ æ–‡ä»¶ç±»å‹: {uploaded_file.type}")
                    print(f"[ç¬¬{i+1}æ­¥] ğŸ”„ è°ƒç”¨VisionProcessor.process_image()...")
                    
                    vision_result = self.vision_processor.process_image(uploaded_file.getvalue(), uploaded_file=uploaded_file)
                    
                    print(f"[ç¬¬{i+1}æ­¥] âœ… GLM-4V-Flashå¤„ç†å®Œæˆ")
                    print(f"[ç¬¬{i+1}æ­¥] ğŸ¯ è¯†åˆ«æˆåŠŸ: {vision_result['success']}")
                    if vision_result['success']:
                        print(f"[ç¬¬{i+1}æ­¥] ğŸ“ è¯†åˆ«æ–‡æœ¬é•¿åº¦: {len(vision_result.get('raw_text', ''))} å­—ç¬¦")
                        print(f"[ç¬¬{i+1}æ­¥] ğŸ¯ ç½®ä¿¡åº¦: {vision_result.get('confidence', 0)}")
                    else:
                        print(f"[ç¬¬{i+1}æ­¥] âŒ è¯†åˆ«å¤±è´¥åŸå› : {vision_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
                    # è°ƒè¯•ï¼šæ˜¾ç¤ºè§†è§‰è¯†åˆ«ç»“æœ
                    st.write("**è°ƒè¯•ä¿¡æ¯ - GLM-4V-Flashè¯†åˆ«ç»“æœï¼š**")
                    st.json(vision_result)
                    
                    # æ­¥éª¤2: AIå¢å¼ºå¤„ç†
                    if vision_result['success']:
                        status_text.text(f"ğŸ¤– æ­¥éª¤2: AIåˆ†æå’Œå¢å¼º - {uploaded_file.name}")
                        st.info(f"è¯†åˆ«åˆ°çš„æ–‡æœ¬é•¿åº¦: {len(vision_result.get('raw_text', ''))}")
                        print(f"[å¤„ç†] å¼€å§‹AIåˆ†æï¼Œæ–‡æœ¬é•¿åº¦: {len(vision_result.get('raw_text', ''))}")
                        
                        try:
                            enhanced_result = self.ai_analyzer.process_image_with_ai(
                                vision_result, f"è‹±è¯­æ•™æ - {uploaded_file.name}"
                            )
                            # è°ƒè¯•ï¼šæ˜¾ç¤ºAIå¢å¼ºç»“æœ
                            st.write("**è°ƒè¯•ä¿¡æ¯ - AIå¢å¼ºç»“æœï¼š**")
                            st.json(enhanced_result)
                            
                            enhanced_result['filename'] = uploaded_file.name
                            results.append(enhanced_result)
                            st.session_state.processed_count += 1
                        except Exception as ai_error:
                            print(f"[å¤„ç†] AIåˆ†æå¤±è´¥: {ai_error}")
                            st.error(f"AIå¤„ç†å¤±è´¥: {ai_error}")
                            # åˆ›å»ºåŸºæœ¬çš„é”™è¯¯ç»“æœ
                            enhanced_result = {
                                'success': False,
                                'error': str(ai_error),
                                'raw_text': vision_result.get('raw_text', ''),
                                'confidence': vision_result.get('confidence', 0),
                                'analysis': {}
                            }
                            enhanced_result['filename'] = uploaded_file.name
                            results.append(enhanced_result)
                    else:
                        print(f"[å¤„ç†] è§†è§‰è¯†åˆ«å¤±è´¥: {vision_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        st.error(f"è§†è§‰è¯†åˆ«å¤±è´¥: {vision_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                        continue
                    
                except Exception as e:
                    print(f"[å¤„ç†] å¤„ç† {uploaded_file.name} å¼‚å¸¸: {e}")
                    print(f"[å¤„ç†] å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}")
                    import traceback
                    print(f"[å¤„ç†] å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
                    st.error(f"å¤„ç† {uploaded_file.name} æ—¶å‡ºé”™: {e}")
                
                progress_bar.progress((i + 1) / len(uploaded_files))
            
            status_text.text("âœ… å¤„ç†å®Œæˆï¼")
            return {'results': results, 'source': 'upload'}
        
        return None
    
    def _process_folder(self, folder_path: str, settings: Dict) -> Optional[Dict]:
        """å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡"""
        try:
            # æ‰«æå›¾ç‰‡æ–‡ä»¶
            image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']
            image_files = []
            
            for ext in image_extensions:
                image_files.extend(Path(folder_path).glob(f"*{ext}"))
                image_files.extend(Path(folder_path).glob(f"*{ext.upper()}"))
            
            if not image_files:
                st.warning("æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
                return None
            
            st.success(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
            
            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨é¢„è§ˆ
            with st.expander("ğŸ“ æ–‡ä»¶åˆ—è¡¨é¢„è§ˆ"):
                for file_path in image_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    st.text(file_path.name)
                if len(image_files) > 10:
                    st.text(f"... è¿˜æœ‰ {len(image_files) - 10} ä¸ªæ–‡ä»¶")
            
            if st.button("ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†", type="primary"):
                return self._batch_process_images(image_files, settings)
                
        except Exception as e:
            st.error(f"æ‰«ææ–‡ä»¶å¤¹å¤±è´¥: {e}")
        
        return None
    
    def _batch_process_images(self, image_files: List[Path], settings: Dict) -> Optional[Dict]:
        """æ‰¹é‡å¤„ç†å›¾ç‰‡"""
        if not self._initialize_processors():
            return None
        
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # åˆ›å»ºå¤„ç†ç»“æœè¡¨æ ¼
        result_container = st.container()
        
        for i, image_path in enumerate(image_files):
            # è¯¦ç»†å¤„ç†æ­¥éª¤æ—¥å¿—
            status_text.text(f"ğŸ“ æ­£åœ¨å¤„ç†æ–‡ä»¶: {image_path.name} ({i+1}/{len(image_files)})")
            
            try:
                # æ­¥éª¤1: GLM-4V-Flashè§†è§‰è¯†åˆ«
                status_text.text(f"ğŸ” æ­¥éª¤1: GLM-4V-Flashè§†è§‰è¯†åˆ« - {image_path.name}")
                print(f"[æ‰¹é‡å¤„ç†] å¼€å§‹å¤„ç†æ–‡ä»¶: {image_path.name}")
                vision_result = self.vision_processor.process_image(str(image_path), uploaded_file=None)
                print(f"[æ‰¹é‡å¤„ç†] è§†è§‰è¯†åˆ«å®Œæˆï¼ŒæˆåŠŸ: {vision_result['success']}")
                
                # è°ƒè¯•ï¼šæ˜¾ç¤ºè§†è§‰è¯†åˆ«ç»“æœ
                st.write("**è°ƒè¯•ä¿¡æ¯ - GLM-4V-Flashè¯†åˆ«ç»“æœï¼š**")
                st.json(vision_result)
                
                # æ­¥éª¤2: AIå¢å¼ºå¤„ç†
                if vision_result['success']:
                    status_text.text(f"ğŸ¤– æ­¥éª¤2: AIåˆ†æå’Œå¢å¼º - {image_path.name}")
                    st.info(f"è¯†åˆ«åˆ°çš„æ–‡æœ¬é•¿åº¦: {len(vision_result.get('raw_text', ''))}")
                    print(f"[æ‰¹é‡å¤„ç†] å¼€å§‹AIåˆ†æï¼Œæ–‡æœ¬é•¿åº¦: {len(vision_result.get('raw_text', ''))}")
                    time.sleep(0.5)  # è®©ç”¨æˆ·çœ‹åˆ°å¤„ç†æ­¥éª¤
                    
                    try:
                        enhanced_result = self.ai_analyzer.process_image_with_ai(
                            vision_result, f"è‹±è¯­æ•™æ - {image_path.name}"
                        )
                        st.write("**è°ƒè¯•ä¿¡æ¯ - AIå¢å¼ºç»“æœï¼š**")
                        st.json(enhanced_result)
                    except Exception as ai_error:
                        print(f"[æ‰¹é‡å¤„ç†] AIåˆ†æå¤±è´¥: {ai_error}")
                        st.error(f"AIå¤„ç†å¤±è´¥: {ai_error}")
                        # åˆ›å»ºåŸºæœ¬çš„é”™è¯¯ç»“æœ
                        enhanced_result = {
                            'success': False,
                            'error': str(ai_error),
                            'raw_text': vision_result.get('raw_text', ''),
                            'confidence': vision_result.get('confidence', 0),
                            'analysis': {}
                        }
                else:
                    print(f"[æ‰¹é‡å¤„ç†] è§†è§‰è¯†åˆ«å¤±è´¥: {vision_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    st.error(f"è§†è§‰è¯†åˆ«å¤±è´¥: {vision_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    continue
                
                # æ­¥éª¤3: æ•´ç†ç»“æœ
                status_text.text(f"ğŸ“ æ­¥éª¤3: æ•´ç†å’Œåˆ†ç±»å†…å®¹ - {image_path.name}")
                enhanced_result['filename'] = image_path.name
                enhanced_result['filepath'] = str(image_path)
                results.append(enhanced_result)
                st.session_state.processed_count += 1
                
                # æ­¥éª¤4: æ˜¾ç¤ºå®ŒæˆçŠ¶æ€
                status_text.text(f"âœ… å®Œæˆå¤„ç†: {image_path.name}")
                time.sleep(0.3)
                
                # å®æ—¶æ˜¾ç¤ºå¤„ç†ç»“æœ
                with result_container:
                    if len(results) == 1:
                        st.markdown("### ğŸ“Š å¤„ç†ç»“æœ")
                    
                    col1, col2, col3 = st.columns([2, 1, 1])
                    with col1:
                        st.text(f"âœ… {image_path.name}")
                    with col2:
                        st.text(f"ç½®ä¿¡åº¦: {enhanced_result.get('confidence', 0):.2f}")
                    with col3:
                        analysis = enhanced_result.get('analysis', {})
                        st.text(f"ç±»å‹: {analysis.get('content_type', 'æœªçŸ¥')}")
                
            except Exception as e:
                st.error(f"å¤„ç† {image_path.name} å¤±è´¥: {e}")
                
            progress_bar.progress((i + 1) / len(image_files))
        
        status_text.text("âœ… æ‰¹é‡å¤„ç†å®Œæˆï¼")
        return {'results': results, 'source': 'folder'}
    
    def _display_uploaded_images(self, uploaded_files: List) -> Dict:
        """å‡†å¤‡å›¾ç‰‡æ–‡ä»¶å¹¶æä¾›AIå¤„ç†é€‰é¡¹"""
        st.success(f"âœ… å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        results = []
        
        # ç®€åŒ–æ˜¾ç¤ºï¼šåªæ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨å’Œå¤„ç†çŠ¶æ€
        st.markdown("### ğŸ“ ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨")
        
        for i, uploaded_file in enumerate(uploaded_files):
            # ä¿å­˜æ–‡ä»¶åˆ°staticç›®å½•å¹¶è·å–URL
            image_url = self._save_file_to_static_and_get_url(uploaded_file)
            
            # ç®€æ´çš„æ–‡ä»¶ä¿¡æ¯æ˜¾ç¤º
            col1, col2, col3 = st.columns([3, 2, 1])
            with col1:
                st.write(f"**{i+1}. {uploaded_file.name}**")
            with col2:
                st.write(f"ğŸ“Š {uploaded_file.size:,} bytes")
            with col3:
                if image_url:
                    st.write("âœ… å°±ç»ª")
                else:
                    st.write("âŒ å¤±è´¥")
            
            # è®°å½•ç»“æœï¼ˆåŒ…å«URLï¼‰
            results.append({
                'filename': uploaded_file.name,
                'size': uploaded_file.size,
                'type': uploaded_file.type,
                'url': image_url,
                'displayed': True
            })
        
        # æ·»åŠ AIå¤„ç†æŒ‰é’®
        st.markdown("---")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ¤– å¼€å§‹AIè¯†åˆ«å¤„ç†", type="primary", use_container_width=True):
                return self._process_images_with_ai(uploaded_files, results)
        with col2:
            if st.button("âŒ å–æ¶ˆ", type="secondary", use_container_width=True):
                # æ¸…ç†å·²ä¸Šä¼ çš„æ–‡ä»¶
                self._cleanup_static_files(results)
                st.warning("å·²å–æ¶ˆå¹¶æ¸…ç†æ–‡ä»¶")
                return None
        
        st.info("ğŸ’¡ æ–‡ä»¶å·²å‡†å¤‡å°±ç»ªã€‚ç‚¹å‡»"å¼€å§‹AIè¯†åˆ«å¤„ç†"æŒ‰é’®è¿›è¡Œå¤„ç†ã€‚")
        return {'results': results, 'source': 'upload_display_only'}
    
    def _save_file_to_static_and_get_url(self, uploaded_file) -> Optional[str]:
        """å°†ä¸Šä¼ æ–‡ä»¶ä¿å­˜åˆ°staticç›®å½•å¹¶ç”Ÿæˆå¯è®¿é—®URL"""
        try:
            import os
            import uuid
            import time
            from pathlib import Path
            
            # ç¡®ä¿staticç›®å½•å­˜åœ¨
            project_root = Path(__file__).parent.parent.parent  # å›åˆ°é¡¹ç›®æ ¹ç›®å½•
            static_dir = project_root / "static"
            static_dir.mkdir(exist_ok=True)
            
            print(f"[Staticä¿å­˜] é¡¹ç›®æ ¹ç›®å½•: {project_root}")
            print(f"[Staticä¿å­˜] Staticç›®å½•: {static_dir}")
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            timestamp = int(time.time())
            file_extension = uploaded_file.name.split('.')[-1] if '.' in uploaded_file.name else 'jpg'
            unique_id = str(uuid.uuid4())[:8]
            filename = f"upload_{timestamp}_{unique_id}.{file_extension}"
            
            # å®Œæ•´æ–‡ä»¶è·¯å¾„
            file_path = static_dir / filename
            
            # ä¿å­˜æ–‡ä»¶
            with open(file_path, 'wb') as f:
                f.write(uploaded_file.getvalue())
            
            print(f"[Staticä¿å­˜] âœ… æ–‡ä»¶å·²ä¿å­˜: {file_path}")
            print(f"[Staticä¿å­˜] æ–‡ä»¶å¤§å°: {os.path.getsize(file_path)} bytes")
            
            # ç”ŸæˆURL
            # æ£€æµ‹è¿è¡Œç¯å¢ƒ
            is_cloud = self._detect_cloud_environment()
            
            if is_cloud:
                base_url = "https://engirl.streamlit.app"
            else:
                base_url = "http://localhost:8501"  # æœ¬åœ°é»˜è®¤ç«¯å£
            
            # æ„é€ é™æ€æ–‡ä»¶URL
            static_url = f"{base_url}/static/{filename}"
            
            print(f"[Staticä¿å­˜] âœ… ç”Ÿæˆçš„é™æ€URL: {static_url}")
            print(f"[Staticä¿å­˜] URLç»„æˆ:")
            print(f"  - åŸºç¡€URL: {base_url}")
            print(f"  - é™æ€è·¯å¾„: /static/{filename}")
            
            return static_url
            
        except Exception as e:
            print(f"[Staticä¿å­˜] âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _detect_cloud_environment(self) -> bool:
        """æ£€æµ‹æ˜¯å¦åœ¨äº‘ç¯å¢ƒä¸­è¿è¡Œ"""
        import os
        
        # æ£€æŸ¥Streamlit Cloudç¯å¢ƒå˜é‡
        cloud_indicators = [
            'STREAMLIT_SHARING_MODE',
            'STREAMLIT_CLOUD',
            ('HOSTNAME', lambda x: 'streamlit' in str(x).lower()),
            ('SERVER_NAME', lambda x: 'streamlit.app' in str(x).lower())
        ]
        
        for indicator in cloud_indicators:
            if isinstance(indicator, tuple):
                var_name, check_func = indicator
                if var_name in os.environ and check_func(os.environ[var_name]):
                    print(f"[ç¯å¢ƒæ£€æµ‹] é€šè¿‡ {var_name}={os.environ[var_name]} æ£€æµ‹åˆ°äº‘ç¯å¢ƒ")
                    return True
            else:
                if indicator in os.environ:
                    print(f"[ç¯å¢ƒæ£€æµ‹] é€šè¿‡ {indicator} æ£€æµ‹åˆ°äº‘ç¯å¢ƒ")
                    return True
        
        print(f"[ç¯å¢ƒæ£€æµ‹] æ£€æµ‹åˆ°æœ¬åœ°ç¯å¢ƒ")
        return False
    
    def _process_images_with_ai(self, uploaded_files: List, file_results: List[Dict]) -> Dict:
        """ä½¿ç”¨AIå¤„ç†å›¾ç‰‡å¹¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        st.markdown("### ğŸ¤– AIè¯†åˆ«å¤„ç†ä¸­...")
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        if not self._initialize_processors():
            st.error("âŒ å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥")
            return None
        
        processed_results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, (uploaded_file, file_info) in enumerate(zip(uploaded_files, file_results)):
            status_text.text(f"ğŸ” æ­£åœ¨å¤„ç†: {uploaded_file.name}")
            
            try:
                # è·å–é™æ€URL
                static_url = file_info.get('url')
                if not static_url:
                    st.error(f"âŒ æ— æ³•è·å–æ–‡ä»¶URL: {uploaded_file.name}")
                    continue
                
                print(f"\n[AIå¤„ç†] ==================== å¼€å§‹AIè¯†åˆ« ====================")
                print(f"[AIå¤„ç†] ğŸ“ æ–‡ä»¶å: {uploaded_file.name}")
                print(f"[AIå¤„ç†] ğŸ”— é™æ€URL: {static_url}")
                print(f"[AIå¤„ç†] ğŸ“Š æ–‡ä»¶å¤§å°: {uploaded_file.size} bytes")
                
                # è°ƒç”¨GLM-4V-Flashè¿›è¡Œè¯†åˆ«
                status_text.text(f"ğŸ” GLM-4V-Flashè¯†åˆ«ä¸­: {uploaded_file.name}")
                
                # ä½¿ç”¨é™æ€URLè°ƒç”¨AIè¯†åˆ«
                vision_result = self.vision_processor.process_image(static_url, uploaded_file=None)  # ä¼ é€’URLè€Œéæ–‡ä»¶
                
                print(f"[AIå¤„ç†] âœ… GLM-4V-Flashå¤„ç†å®Œæˆ")
                print(f"[AIå¤„ç†] ğŸ¯ è¯†åˆ«æˆåŠŸ: {vision_result['success']}")
                
                if vision_result['success']:
                    print(f"[AIå¤„ç†] ğŸ“ è¯†åˆ«æ–‡æœ¬é•¿åº¦: {len(vision_result.get('raw_text', ''))} å­—ç¬¦")
                    
                    # AIå¢å¼ºå¤„ç†
                    status_text.text(f"ğŸ¤– AIåˆ†æå¢å¼ºä¸­: {uploaded_file.name}")
                    enhanced_result = self.ai_analyzer.process_image_with_ai(
                        vision_result, f"è‹±è¯­æ•™æ - {uploaded_file.name}"
                    )
                    
                    result = {
                        'filename': uploaded_file.name,
                        'static_url': static_url,
                        'success': True,
                        'vision_result': vision_result,
                        'enhanced_result': enhanced_result,
                        'file_path': self._get_static_file_path(static_url)  # ç”¨äºåç»­æ¸…ç†
                    }
                    
                    st.success(f"âœ… {uploaded_file.name} å¤„ç†å®Œæˆ")
                    
                else:
                    print(f"[AIå¤„ç†] âŒ è¯†åˆ«å¤±è´¥: {vision_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    result = {
                        'filename': uploaded_file.name,
                        'static_url': static_url,
                        'success': False,
                        'error': vision_result.get('error', 'è¯†åˆ«å¤±è´¥'),
                        'file_path': self._get_static_file_path(static_url)
                    }
                    st.error(f"âŒ {uploaded_file.name} å¤„ç†å¤±è´¥: {result['error']}")
                
                processed_results.append(result)
                
            except Exception as e:
                error_msg = f"å¤„ç†å¼‚å¸¸: {e}"
                print(f"[AIå¤„ç†] âŒ {error_msg}")
                st.error(f"âŒ {uploaded_file.name}: {error_msg}")
                
                processed_results.append({
                    'filename': uploaded_file.name,
                    'static_url': file_info.get('url'),
                    'success': False,
                    'error': error_msg,
                    'file_path': self._get_static_file_path(file_info.get('url')) if file_info.get('url') else None
                })
            
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        # å¤„ç†å®Œæˆåæ¸…ç†ä¸´æ—¶æ–‡ä»¶
        st.markdown("### ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        cleanup_results = self._cleanup_static_files(processed_results)
        
        status_text.text("âœ… æ‰€æœ‰å¤„ç†å®Œæˆï¼")
        
        final_result = {
            'results': processed_results,
            'source': 'ai_processed',
            'cleanup_summary': cleanup_results
        }
        
        return final_result
    
    def _get_static_file_path(self, static_url: str) -> Optional[str]:
        """ä»é™æ€URLè·å–æœ¬åœ°æ–‡ä»¶è·¯å¾„"""
        if not static_url:
            return None
        
        try:
            from pathlib import Path
            # ä»URLä¸­æå–æ–‡ä»¶å
            filename = static_url.split('/')[-1]
            
            # æ„é€ æœ¬åœ°æ–‡ä»¶è·¯å¾„
            project_root = Path(__file__).parent.parent.parent
            static_dir = project_root / "static"
            file_path = static_dir / filename
            
            return str(file_path) if file_path.exists() else None
        except Exception as e:
            print(f"[æ–‡ä»¶è·¯å¾„] âŒ è·å–æ–‡ä»¶è·¯å¾„å¤±è´¥: {e}")
            return None
    
    def _cleanup_static_files(self, processed_results: List[Dict]) -> Dict:
        """æ¸…ç†å¤„ç†å®Œæˆçš„é™æ€æ–‡ä»¶"""
        cleanup_summary = {
            'total_files': len(processed_results),
            'deleted_files': 0,
            'failed_deletions': 0,
            'deleted_list': [],
            'failed_list': []
        }
        
        for result in processed_results:
            file_path = result.get('file_path')
            filename = result.get('filename', 'unknown')
            
            if file_path:
                try:
                    import os
                    if os.path.exists(file_path):
                        os.remove(file_path)
                        cleanup_summary['deleted_files'] += 1
                        cleanup_summary['deleted_list'].append(filename)
                        print(f"[æ¸…ç†] âœ… å·²åˆ é™¤: {file_path}")
                    else:
                        print(f"[æ¸…ç†] âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                except Exception as e:
                    cleanup_summary['failed_deletions'] += 1
                    cleanup_summary['failed_list'].append(filename)
                    print(f"[æ¸…ç†] âŒ åˆ é™¤å¤±è´¥ {file_path}: {e}")
            else:
                print(f"[æ¸…ç†] âš ï¸ æ— æ³•è·å–æ–‡ä»¶è·¯å¾„: {filename}")
        
        # æ˜¾ç¤ºæ¸…ç†ç»“æœ
        if cleanup_summary['deleted_files'] > 0:
            st.success(f"ğŸ§¹ å·²æ¸…ç† {cleanup_summary['deleted_files']} ä¸ªä¸´æ—¶æ–‡ä»¶")
        
        if cleanup_summary['failed_deletions'] > 0:
            st.warning(f"âš ï¸ {cleanup_summary['failed_deletions']} ä¸ªæ–‡ä»¶æ¸…ç†å¤±è´¥")
        
        print(f"[æ¸…ç†] ğŸ“Š æ¸…ç†ç»Ÿè®¡: {cleanup_summary}")
        return cleanup_summary
    
    def _initialize_processors(self) -> bool:
        """åˆå§‹åŒ–å¤„ç†å™¨"""
        try:
            print(f"[åˆå§‹åŒ–] å¼€å§‹åˆå§‹åŒ–å¤„ç†å™¨...")
            
            if self.vision_processor is None:
                with st.spinner("åˆå§‹åŒ–GLM-4V-Flashè§†è§‰è¯†åˆ«å¼•æ“..."):
                    print(f"[åˆå§‹åŒ–] åˆ›å»ºè§†è§‰å¤„ç†å™¨...")
                    self.vision_processor = create_vision_processor()
            
            if self.ai_analyzer is None:
                with st.spinner("åˆå§‹åŒ–AIåˆ†æå¼•æ“..."):
                    print(f"[åˆå§‹åŒ–] åˆ›å»ºAIåˆ†æå™¨...")
                    self.ai_analyzer = create_ai_enhanced_ocr()
            
            if self.doc_generator is None:
                print(f"[åˆå§‹åŒ–] åˆ›å»ºæ–‡æ¡£ç”Ÿæˆå™¨...")
                self.doc_generator = DocumentGenerator()
            
            print(f"[åˆå§‹åŒ–] å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"[åˆå§‹åŒ–] åˆå§‹åŒ–å¤±è´¥: {e}")
            st.error(f"åˆå§‹åŒ–å¤„ç†å™¨å¤±è´¥: {e}")
            return False
    
    def render_results_section(self, processing_results: Dict):
        """æ¸²æŸ“å¤„ç†ç»“æœåŒºåŸŸ"""
        if not processing_results or not processing_results.get('results'):
            return
        
        results = processing_results['results']
        source = processing_results.get('source', 'unknown')
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯çº¯æ˜¾ç¤ºæ¨¡å¼
        if source == 'upload_display_only':
            st.markdown("### ğŸ“Š å›¾ç‰‡ä¸Šä¼ ç»Ÿè®¡")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ä¸Šä¼ æ–‡ä»¶æ•°", len(results))
            with col2:
                total_size = sum(r.get('size', 0) for r in results)
                st.metric("æ€»å¤§å°", f"{total_size:,} bytes")
            with col3:
                image_types = set(r.get('type', '') for r in results)
                st.metric("æ–‡ä»¶ç±»å‹æ•°", len(image_types))
            with col4:
                st.metric("æ˜¾ç¤ºçŠ¶æ€", "âœ… å…¨éƒ¨æ˜¾ç¤º")
            
            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            st.markdown("### ğŸ“ ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨")
            for i, result in enumerate(results):
                st.write(f"{i+1}. **{result['filename']}** ({result['size']} bytes, {result['type']})")
                
            return
        
        # åŸæœ‰çš„AIå¤„ç†ç»“æœæ˜¾ç¤ºé€»è¾‘
        st.markdown("### ğŸ“‹ å¤„ç†ç»“æœè¯¦æƒ…")
        
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»æ–‡ä»¶æ•°", len(results))
        with col2:
            successful = sum(1 for r in results if r.get('success'))
            st.metric("æˆåŠŸå¤„ç†", successful)
        with col3:
            avg_confidence = sum(r.get('confidence', 0) for r in results) / len(results) if results else 0
            st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.2f}")
        with col4:
            total_text = sum(len(r.get('corrected_text', '')) for r in results)
            st.metric("æ€»æ–‡æœ¬é•¿åº¦", f"{total_text:,}")
        
        # ç»“æœå±•ç¤ºé€‰é¡¹
        st.markdown("### ğŸ“Š ç»“æœå±•ç¤ºé€‰é¡¹")
        
        # æ·»åŠ æ¨¡å¼è¯´æ˜
        with st.expander("ğŸ“– æ¨¡å¼è¯´æ˜", expanded=False):
            st.markdown("""
            **ğŸ” æ¦‚è§ˆæ¨¡å¼**ï¼šå¿«é€ŸæŸ¥çœ‹æ‰€æœ‰å¤„ç†æ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯
            - æ˜¾ç¤ºè¯†åˆ«æ–‡æœ¬é¢„è§ˆï¼ˆå‰200å­—ç¬¦ï¼‰
            - æ˜¾ç¤ºAIåˆ†æçš„åŸºæœ¬ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€ç±»å‹ã€è¯æ±‡æ•°ç­‰ï¼‰
            - é€‚åˆå¿«é€Ÿæµè§ˆå¤šä¸ªæ–‡ä»¶çš„å¤„ç†ç»“æœ
            
            **ğŸ“‹ è¯¦ç»†æ¨¡å¼**ï¼šæŸ¥çœ‹å•ä¸ªæ–‡ä»¶çš„å®Œæ•´å¤„ç†ç»“æœ
            - æ˜¾ç¤ºå®Œæ•´çš„è¯†åˆ«æ–‡æœ¬å†…å®¹
            - æ˜¾ç¤ºè¯¦ç»†çš„AIåˆ†æç»“æœï¼ˆè¯æ±‡è¡¨ã€è¯­æ³•ç‚¹ã€ç»ƒä¹ é¢˜ç­‰ï¼‰
            - é€‚åˆæ·±å…¥äº†è§£ç‰¹å®šæ–‡ä»¶çš„å†…å®¹
            
            **ğŸ“„ æ–‡æ¡£ç”Ÿæˆ**ï¼šå°†å¤„ç†ç»“æœç”Ÿæˆå­¦ä¹ æ–‡æ¡£
            - ç”Ÿæˆç»“æ„åŒ–çš„Markdownå­¦ä¹ æ–‡æ¡£
            - åŒ…å«è¯¾æ–‡å†…å®¹ã€è¯æ±‡è¡¨ã€è¯­æ³•ç‚¹å’Œç»ƒä¹ é¢˜
            - æ”¯æŒä¸‹è½½ä¿å­˜åˆ°æœ¬åœ°
            """)
        
        view_mode = st.radio(
            "é€‰æ‹©æ˜¾ç¤ºæ¨¡å¼ï¼š",
            ["æ¦‚è§ˆæ¨¡å¼", "è¯¦ç»†æ¨¡å¼", "æ–‡æ¡£ç”Ÿæˆ"],
            horizontal=True
        )
        
        if view_mode == "æ¦‚è§ˆæ¨¡å¼":
            self._render_overview_mode(results)
        elif view_mode == "è¯¦ç»†æ¨¡å¼":
            self._render_detailed_mode(results)
        else:
            self._render_document_generation(results)
    
    def _render_overview_mode(self, results: List[Dict]):
        """æ¸²æŸ“æ¦‚è§ˆæ¨¡å¼"""
        for i, result in enumerate(results):
            with st.expander(f"ğŸ“„ {result.get('filename', f'æ–‡ä»¶{i+1}')}"):
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.markdown("**è¯†åˆ«æ–‡æœ¬é¢„è§ˆï¼š**")
                    text = result.get('corrected_text', '')
                    preview = text[:200] + "..." if len(text) > 200 else text
                    st.text_area("", preview, height=100, disabled=True)
                
                with col2:
                    st.markdown("**åˆ†æä¿¡æ¯ï¼š**")
                    analysis = result.get('analysis', {})
                    st.write(f"- æ ‡é¢˜: {analysis.get('title', 'æœªçŸ¥')}")
                    st.write(f"- ç±»å‹: {analysis.get('content_type', 'æœªçŸ¥')}")
                    st.write(f"- å•å…ƒ: {analysis.get('unit', 'æœªçŸ¥')}")
                    
                    vocab_count = len(analysis.get('vocabulary', []))
                    grammar_count = len(analysis.get('grammar_points', []))
                    st.write(f"- è¯æ±‡æ•°: {vocab_count}")
                    st.write(f"- è¯­æ³•ç‚¹: {grammar_count}")
    
    def _render_detailed_mode(self, results: List[Dict]):
        """æ¸²æŸ“è¯¦ç»†æ¨¡å¼"""
        selected_file = st.selectbox(
            "é€‰æ‹©è¦æŸ¥çœ‹çš„æ–‡ä»¶ï¼š",
            range(len(results)),
            format_func=lambda x: results[x].get('filename', f'æ–‡ä»¶{x+1}')
        )
        
        result = results[selected_file]
        
        # åŸºæœ¬ä¿¡æ¯
        st.markdown("#### ğŸ“Š åŸºæœ¬ä¿¡æ¯")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç½®ä¿¡åº¦", f"{result.get('confidence', 0):.2%}")
        with col2:
            st.metric("ä¿®æ­£æ•°é‡", len(result.get('corrections', [])))
        with col3:
            analysis = result.get('analysis', {})
            st.metric("è¯æ±‡æ•°é‡", len(analysis.get('vocabulary', [])))
        
        # æ–‡æœ¬å¯¹æ¯”
        st.markdown("#### ğŸ“ æ–‡æœ¬å†…å®¹")
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**åŸå§‹OCRæ–‡æœ¬ï¼š**")
            st.text_area("", result.get('raw_ocr', ''), height=200, disabled=True)
        
        with col2:
            st.markdown("**AIæ ¡æ­£æ–‡æœ¬ï¼š**")
            st.text_area("", result.get('corrected_text', ''), height=200, disabled=True)
        
        # ä¿®æ­£è¯¦æƒ…
        corrections = result.get('corrections', [])
        if corrections:
            st.markdown("#### ğŸ” ä¿®æ­£è¯¦æƒ…")
            for correction in corrections:
                st.markdown(f"- `{correction.get('original', '')}` â†’ `{correction.get('corrected', '')}` ({correction.get('reason', '')})")
        
        # åˆ†æç»“æœ
        analysis = result.get('analysis', {})
        if analysis:
            st.markdown("#### ğŸ§  AIåˆ†æç»“æœ")
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**è¯æ±‡åˆ—è¡¨ï¼š**")
                vocabulary = analysis.get('vocabulary', [])
                for vocab in vocabulary:
                    st.markdown(f"- **{vocab.get('word', '')}**: {vocab.get('meaning', '')} ({vocab.get('level', '')})")
            
            with col2:
                st.markdown("**è¯­æ³•ç‚¹ï¼š**")
                grammar_points = analysis.get('grammar_points', [])
                for point in grammar_points:
                    st.markdown(f"- {point}")
    
    def _render_document_generation(self, results: List[Dict]):
        """æ¸²æŸ“æ–‡æ¡£ç”Ÿæˆæ¨¡å¼"""
        st.markdown("#### ğŸ“š æ–‡æ¡£ç”Ÿæˆè®¾ç½®")
        
        col1, col2 = st.columns(2)
        with col1:
            output_dir = st.text_input(
                "è¾“å‡ºç›®å½•",
                value="./output",
                help="ç”Ÿæˆæ–‡æ¡£çš„ä¿å­˜ç›®å½•"
            )
        
        with col2:
            doc_format = st.selectbox(
                "æ–‡æ¡£æ ¼å¼",
                ["markdown", "html", "pdf"],
                help="é€‰æ‹©ç”Ÿæˆæ–‡æ¡£çš„æ ¼å¼"
            )
        
        # ç”Ÿæˆé€‰é¡¹
        st.markdown("**ç”Ÿæˆå†…å®¹é€‰æ‹©ï¼š**")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            gen_lessons = st.checkbox("è¯¾æ–‡æ–‡æ¡£", value=True)
        with col2:
            gen_vocab = st.checkbox("è¯æ±‡è¡¨", value=True)
        with col3:
            gen_exercises = st.checkbox("ç»ƒä¹ é¢˜", value=True)
        with col4:
            gen_index = st.checkbox("ç´¢å¼•ç›®å½•", value=True)
        
        if st.button("ğŸ¯ ç”Ÿæˆæ–‡æ¡£", type="primary"):
            if not self.doc_generator:
                self.doc_generator = DocumentGenerator()
            
            try:
                with st.spinner("æ­£åœ¨ç”Ÿæˆæ–‡æ¡£..."):
                    # ç»„ç»‡æ•°æ®
                    lessons = []
                    vocabulary = []
                    
                    for result in results:
                        analysis = result.get('analysis', {})
                        
                        # è¯¾æ–‡æ•°æ®
                        lesson_data = {
                            'unit': analysis.get('unit'),
                            'title': analysis.get('title', result.get('filename', '')),
                            'content_type': analysis.get('content_type'),
                            'content': result.get('corrected_text', ''),
                            'vocabulary': analysis.get('vocabulary', []),
                            'grammar_points': analysis.get('grammar_points', [])
                        }
                        lessons.append(lesson_data)
                        
                        # è¯æ±‡æ•°æ®
                        vocab_list = analysis.get('vocabulary', [])
                        for vocab in vocab_list:
                            vocab['unit'] = analysis.get('unit')
                            vocabulary.append(vocab)
                    
                    # ç”Ÿæˆæ–‡æ¡£
                    generated_files = []
                    
                    if gen_lessons:
                        lesson_file = self.doc_generator.generate_lesson_document(
                            lessons, output_dir, doc_format
                        )
                        if lesson_file:
                            generated_files.append(lesson_file)
                    
                    if gen_vocab:
                        vocab_file = self.doc_generator.generate_vocabulary_document(
                            vocabulary, output_dir, doc_format
                        )
                        if vocab_file:
                            generated_files.append(vocab_file)
                    
                    if gen_exercises:
                        # ç”Ÿæˆç»ƒä¹ é¢˜éœ€è¦AI
                        exercises_data = []
                        for lesson in lessons:
                            exercises = self.ai_ocr.analyzer.generate_exercises(
                                lesson['content'], lesson['vocabulary']
                            )
                            exercises_data.append({
                                'unit': lesson['unit'],
                                'title': lesson['title'],
                                'exercises': exercises
                            })
                        
                        exercise_file = self.doc_generator.generate_exercise_document(
                            exercises_data, output_dir, doc_format
                        )
                        if exercise_file:
                            generated_files.append(exercise_file)
                    
                    if gen_index and generated_files:
                        index_file = self.doc_generator.generate_index_document(
                            generated_files, output_dir, doc_format
                        )
                        if index_file:
                            generated_files.append(index_file)
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.success(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_files)} ä¸ªæ–‡æ¡£ï¼")
                    st.session_state.generated_docs += len(generated_files)
                    
                    # æ·»åŠ ä¸‹è½½åŠŸèƒ½
                    st.markdown("### ğŸ“¥ ä¸‹è½½ç”Ÿæˆçš„æ–‡æ¡£")
                    
                    for file_path in generated_files:
                        if os.path.exists(file_path):
                            filename = os.path.basename(file_path)
                            
                            # è¯»å–æ–‡ä»¶å†…å®¹
                            with open(file_path, 'r', encoding='utf-8') as f:
                                file_content = f.read()
                            
                            col1, col2 = st.columns([3, 1])
                            with col1:
                                st.markdown(f"ğŸ“„ **{filename}**")
                                # æ˜¾ç¤ºæ–‡ä»¶é¢„è§ˆ
                                with st.expander(f"é¢„è§ˆ {filename}"):
                                    if filename.endswith('.md'):
                                        st.markdown(file_content)
                                    else:
                                        st.text(file_content)
                            
                            with col2:
                                # æ·»åŠ ä¸‹è½½æŒ‰é’®
                                st.download_button(
                                    label="ğŸ’¾ ä¸‹è½½",
                                    data=file_content,
                                    file_name=filename,
                                    mime="text/markdown" if filename.endswith('.md') else "text/plain",
                                    key=f"download_{filename}"
                                )
                        else:
                            st.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                
            except Exception as e:
                st.error(f"æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {e}")
    
    def run(self):
        """è¿è¡Œä¸»ç•Œé¢"""
        self.setup_page_config()
        self.render_header()
        
        # æ¸²æŸ“ä¾§è¾¹æ 
        settings = self.render_sidebar()
        
        # ä¸»è¦å†…å®¹åŒºåŸŸ
        processing_results = self.render_image_upload_section(settings)
        
        # è°ƒè¯•ï¼šæ£€æŸ¥å¤„ç†ç»“æœ
        print(f"[ä¸»ç•Œé¢] processing_results: {processing_results}")
        
        if processing_results:
            print(f"[ä¸»ç•Œé¢] å¼€å§‹æ¸²æŸ“ç»“æœåŒºåŸŸ")
            self.render_results_section(processing_results)
        else:
            print(f"[ä¸»ç•Œé¢] æ²¡æœ‰å¤„ç†ç»“æœéœ€è¦æ˜¾ç¤º")
        
        # é¡µè„š
        st.markdown("---")
        st.markdown(
            f'<p style="text-align: center; color: #666; font-size: 0.8rem;">'
            f'ğŸ¤– çº¯AIè§†è§‰è¯†åˆ«ç³»ç»Ÿ {self.version} | åŸºäºæ™ºæ™®AI GLM-4V-Flash + GLM-4-Flash'
            '</p>',
            unsafe_allow_html=True
        )
        print(f"[UI] æ¸²æŸ“é¡µè„šï¼Œç‰ˆæœ¬: {self.version}")


def create_main_interface() -> EnglishLearningInterface:
    """åˆ›å»ºä¸»ç•Œé¢å®ä¾‹"""
    return EnglishLearningInterface()